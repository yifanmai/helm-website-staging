- title: Lite
  description: >-
    Lightweight, broad evaluation of the capabilities of language models using
    in-context learning
  id: lite
  releases:
    - v1.13.0
    - v1.12.0
    - v1.11.0
    - v1.10.0
    - v1.9.0
    - v1.8.0
    - v1.7.0
    - v1.6.0
    - v1.5.0
    - v1.4.0
    - v1.3.0
    - v1.2.0
    - v1.1.0
    - v1.0.0

- title: Classic
  description: >-
    Thorough language model evaluations based on the scenarios from the original
    HELM paper
  id: classic
  benchmark_output_storage: classic
  releases:
    - v0.4.0
  legacy_releases:
    - v0.3.0
    - v0.2.4
    - v0.2.3
    - v0.2.2

- title: HEIM
  description: Holistic evaluation of text-to-image models
  id: heim
  suites_only: true
  releases:
    - v1.1.0
    - v1.0.0

# broken
- title: Instruct
  description: Evaluations of instruction following models with absolute ratings
  id: instruct
  benchmark_output_storage: nlp
  releases:
    - v1.0.0

- title: MMLU
  description: >-
    Massive Multitask Language Understanding (MMLU) evaluations using
    standardized prompts
  id: mmlu
  releases:
    - v1.13.0
    - v1.12.0
    - v1.11.0
    - v1.10.0
    - v1.9.0
    - v1.8.0
    - v1.7.0
    - v1.6.0
    - v1.5.0
    - v1.4.0
    - v1.3.0
    - v1.2.0
    - v1.1.0
    - v1.0.0

- title: VHELM
  description: Holistic Evaluation of Vision-Language Models
  id: vhelm
  suites_only: true
  preview_releases:
    - v2.1.2
    - v2.1.1
  releases:
    - v2.1.0
    - v2.0.1
    - v2.0.0
    - v1.0.0

# broken
- title: Image2Struct
  description: >-
    Evaluations of Vision-Language Models on extracting structured information
    from images
  id: image2struct
  suites_only: true
  releases:
    - v1.0.2
    - v1.0.1
    - v1.0.0

- title: AIR-Bench
  description: >-
    Safety benchmark based on emerging government regulations and company
    policies
  id: air-bench
  releases:
    - v1.6.0
    - v1.5.0
    - v1.4.0
    - v1.3.0
    - v1.2.0
    - v1.1.0
    - v1.0.0

- title: Safety
  description: >-
    Safety benchmark that aggregates popular safety benchmarks across 6 risk
    vectors
  id: safety
  releases:
    - v1.2.0
    - v1.1.0
    - v1.0.0

- title: CLEVA
  description: >-
    Chinese-language benchmark for holistic evaluation of Chinese language
    models
  id: cleva
  releases:
    - v1.0.0

- title: ThaiExam
  description: >-
    Thai-language evaluations of language models on standardized examinations in
    Thailand
  id: thaiexam
  releases:
    - v1.1.0
    - v1.0.0

- title: SEA-HELM
  description: Assessment of large language models across various tasks, emphasizing Southeast Asian languages
  id: seahelm
  benchmark_output_storage: nlp
  releases:
    - v1.0.0

- title: MMLU-Winogrande-Afr
  description: Clinical MMLU and Winogrande in 11 low-resource African languages
  id: mmlu-winogrande-afr
  releases:
    - v1.0.0

- title: ToRR
  description: A benchmark for table reasoning and robustness
  id: torr
  releases:
    - v1.0.0

- title: MedHELM
  description: A benchmark by medical experts for LLMs grounded in real-world healthcare needs
  id: medhelm
  benchmark_output_storage: nlp
  releases:
    - v1.0.0

# Pre-releases

- title: SQL
  description: SQL
  id: sql
  benchmark_output_storage: nlp
  preview_releases:
    - v0.1.0

- title: Long Context
  description: Long context
  id: long-context
  benchmark_output_storage: nlp
  preview_releases:
    - v0.1.0

- title: Finance
  description: Finance
  id: finance
  benchmark_output_storage: nlp
  preview_releases:
    - v1.0.0

- title: Call Center
  description: Call Center
  id: call-center
  benchmark_output_storage: nlp
  preview_releases:
    - v1.0.0

- title: Capabilities
  description: Capabilities
  id: capabilities
  benchmark_output_storage: nlp
  preview_releases:
    - v1.0.0

- title: Ewok
  description: Ewok
  id: ewok
  preview_releases:
    - v1.0.0

- title: Speech
  description: Speech
  id: speech
  preview_releases:
    - v1.0.0